{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 31)\n",
      "(1459, 30)\n",
      "(1460, 30)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('train.csv')\n",
    "test_data=pd.read_csv('test.csv')\n",
    "\n",
    "train_data['MSSubClass']=train_data['MSSubClass'].apply(str)\n",
    "train_data['OverallCond']=train_data['OverallCond'].astype(str)\n",
    "train_data['YrSold']=train_data['YrSold'].astype(str)\n",
    "train_data['MoSold']=train_data['MoSold'].astype(str)\n",
    "\n",
    "test_data['MSSubClass']=test_data['MSSubClass'].apply(str)\n",
    "test_data['OverallCond']=test_data['OverallCond'].astype(str)\n",
    "test_data['YrSold']=test_data['YrSold'].astype(str)\n",
    "test_data['MoSold']=test_data['MoSold'].astype(str)\n",
    "\n",
    "columns=['MSZoning', 'FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope', 'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', 'YrSold', 'MoSold', 'SaleCondition', 'SaleType', 'LotConfig']\n",
    "for col in columns:\n",
    "    label_enc=LabelEncoder() \n",
    "    label_enc.fit(list(train_data[col].values)) \n",
    "    train_data[col]=label_enc.transform(list(train_data[col].values))\n",
    "    label_enc.fit(list(test_data[col].values)) \n",
    "    test_data[col]=label_enc.transform(list(test_data[col].values))\n",
    "\n",
    "train_data.drop(\"Id\", axis=1, inplace=True)\n",
    "test_data.drop(\"Id\", axis=1, inplace=True)   \n",
    "train_data.drop(\"LandContour\", axis=1, inplace=True)\n",
    "test_data.drop(\"LandContour\", axis=1, inplace=True)\n",
    "train_data.drop(\"Utilities\", axis=1, inplace=True)\n",
    "test_data.drop(\"Utilities\", axis=1, inplace=True)\n",
    "train_data.drop(\"MiscFeature\", axis=1, inplace=True)\n",
    "test_data.drop(\"MiscFeature\", axis=1, inplace=True)\n",
    "train_data.drop(\"Neighborhood\", axis=1, inplace=True)\n",
    "test_data.drop(\"Neighborhood\", axis=1, inplace=True)\n",
    "    \n",
    "for col in train_data.columns:\n",
    "    if(col not in columns+['SalePrice']):\n",
    "        try:\n",
    "            if(col not in 'SalePrice'):\n",
    "                train_data.drop(col, axis=1, inplace=True)\n",
    "                test_data.drop(col, axis=1, inplace=True)\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "    \n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data.head()\n",
    "test_data.head()\n",
    "\n",
    "y_train=train_data.SalePrice.values\n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(train_data.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  Street  Alley  LotShape  LotConfig  LandSlope  \\\n",
       "0           9         3       1      2         3          4          0   \n",
       "1           4         3       1      2         3          2          0   \n",
       "2           9         3       1      2         0          4          0   \n",
       "3          10         3       1      2         0          0          0   \n",
       "4           9         3       1      2         0          2          0   \n",
       "\n",
       "   OverallCond  ExterQual  ExterCond      ...        GarageFinish  GarageQual  \\\n",
       "0            4          2          4      ...                   1           4   \n",
       "1            7          3          4      ...                   1           4   \n",
       "2            4          2          4      ...                   1           4   \n",
       "3            4          3          4      ...                   2           4   \n",
       "4            4          2          4      ...                   1           4   \n",
       "\n",
       "   GarageCond  PavedDrive  PoolQC  Fence  MoSold  YrSold  SaleType  \\\n",
       "0           4           2       3      4       4       2         8   \n",
       "1           4           2       3      4       7       1         8   \n",
       "2           4           2       3      4      11       2         8   \n",
       "3           4           2       3      4       4       0         8   \n",
       "4           4           2       3      4       3       2         8   \n",
       "\n",
       "   SaleCondition  \n",
       "0              4  \n",
       "1              4  \n",
       "2              4  \n",
       "3              0  \n",
       "4              4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression metrics:\n",
      "Training Regression score: 0.6623254810337607\n",
      "Testing Regression score: 0.6726003825698206\n",
      "Training MSE: 20.32319575989016\n",
      "Testing MSE: 22.846252277234505\n",
      "Training MAE: 30.704638945673267\n",
      "Testing MAE 32.36687626519441\n",
      "Training R2 score: 0.6623254810337607\n",
      "Testing R2 score: 0.6726003825698206\n",
      "\n",
      "Lasso regression metrics:\n",
      "Training Regression score: 0.6623730341350089\n",
      "Testing Regression score: 0.6726945147622702\n",
      "Training MSE: 20.320333740604198\n",
      "Testing MSE: 22.83968364458615\n",
      "Training MAE: 30.713303846782047\n",
      "Testing MAE 32.359331613657496\n",
      "Training R2 score: 0.6623730341350089\n",
      "Testing R2 score: 0.6726945147622702\n",
      "\n",
      "Elastic Net regression metrics:\n",
      "Training Regression score: 0.6189523323281737\n",
      "Testing Regression score: 0.6384088257393613\n",
      "Training MSE: 22.93364144754538\n",
      "Testing MSE: 25.232171171188803\n",
      "Training MAE: 32.177202274810206\n",
      "Testing MAE 33.28663915304564\n",
      "Training R2 score: 0.6189523323281737\n",
      "Testing R2 score: 0.6384088257393613\n",
      "\n",
      "XGBoost regression metrics:\n",
      "Training Regression score: 0.8489002805042637\n",
      "Testing Regression score: 0.7202370568077652\n",
      "Training MSE: 9.094050649653434\n",
      "Testing MSE: 19.52212048431751\n",
      "Training MAE: 21.11383604509769\n",
      "Testing MAE 27.756652115613733\n",
      "Training R2 score: 0.8489002805042637\n",
      "Testing R2 score: 0.7202370568077652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(train_data, y_train, test_size=0.3, random_state=42)\n",
    "normalizer=1e8\n",
    "\n",
    "print('Ridge regression metrics:')\n",
    "ridge_cv=RidgeCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X_train, Y_train)\n",
    "print('Training Regression score:', ridge_cv.score(X_train, Y_train))\n",
    "print('Testing Regression score:', ridge_cv.score(X_test, Y_test))\n",
    "print('Training MSE:', mean_squared_error(Y_train, ridge_cv.predict(X_train))/normalizer)\n",
    "print('Testing MSE:', mean_squared_error(Y_test, ridge_cv.predict(X_test))/normalizer)\n",
    "print('Training MAE:', mean_absolute_error(Y_train, ridge_cv.predict(X_train))*1e5/normalizer)\n",
    "print('Testing MAE', mean_absolute_error(Y_test, ridge_cv.predict(X_test))*1e5/normalizer)\n",
    "print('Training R2 score:', r2_score(Y_train, ridge_cv.predict(X_train)))\n",
    "print('Testing R2 score:', r2_score(Y_test, ridge_cv.predict(X_test)))\n",
    "print()\n",
    "\n",
    "print('Lasso regression metrics:')\n",
    "lasso_cv=LassoCV(cv=5, alphas=[1e-3, 1e-2, 1e-1, 1], random_state=0).fit(X_train, Y_train)\n",
    "print('Training Regression score:', lasso_cv.score(X_train, Y_train))\n",
    "print('Testing Regression score:', lasso_cv.score(X_test, Y_test))\n",
    "print('Training MSE:', mean_squared_error(Y_train, lasso_cv.predict(X_train))/normalizer)\n",
    "print('Testing MSE:', mean_squared_error(Y_test, lasso_cv.predict(X_test))/normalizer)\n",
    "print('Training MAE:', mean_absolute_error(Y_train, lasso_cv.predict(X_train))*1e5/normalizer)\n",
    "print('Testing MAE', mean_absolute_error(Y_test,lasso_cv.predict(X_test))*1e5/normalizer)\n",
    "print('Training R2 score:', r2_score(Y_train, lasso_cv.predict(X_train)))\n",
    "print('Testing R2 score:', r2_score(Y_test, lasso_cv.predict(X_test)))\n",
    "print()\n",
    "\n",
    "print('Elastic Net regression metrics:')\n",
    "elastic_net=ElasticNet(random_state=0).fit(X_train, Y_train)\n",
    "print('Training Regression score:', elastic_net.score(X_train, Y_train))\n",
    "print('Testing Regression score:', elastic_net.score(X_test, Y_test))\n",
    "print('Training MSE:', mean_squared_error(Y_train, elastic_net.predict(X_train))/normalizer)\n",
    "print('Testing MSE:', mean_squared_error(Y_test, elastic_net.predict(X_test))/normalizer)\n",
    "print('Training MAE:', mean_absolute_error(Y_train, elastic_net.predict(X_train))*1e5/normalizer)\n",
    "print('Testing MAE', mean_absolute_error(Y_test, elastic_net.predict(X_test))*1e5/normalizer)\n",
    "print('Training R2 score:', r2_score(Y_train, elastic_net.predict(X_train)))\n",
    "print('Testing R2 score:', r2_score(Y_test, elastic_net.predict(X_test)))\n",
    "print()\n",
    "\n",
    "print('XGBoost regression metrics:')\n",
    "xgb=ensemble.GradientBoostingRegressor().fit(X_train, Y_train)\n",
    "print('Training Regression score:', xgb.score(X_train, Y_train))\n",
    "print('Testing Regression score:', xgb.score(X_test, Y_test))\n",
    "print('Training MSE:', mean_squared_error(Y_train, xgb.predict(X_train))/normalizer)\n",
    "print('Testing MSE:', mean_squared_error(Y_test, xgb.predict(X_test))/normalizer)\n",
    "print('Training MAE:', mean_absolute_error(Y_train, xgb.predict(X_train))*1e5/normalizer)\n",
    "print('Testing MAE', mean_absolute_error(Y_test, xgb.predict(X_test))*1e5/normalizer)\n",
    "print('Training R2 score:', r2_score(Y_train, xgb.predict(X_train)))\n",
    "print('Testing R2 score:', r2_score(Y_test, xgb.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishaal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv', delimiter=';')\n",
    "\n",
    "for col in data.columns:\n",
    "    label_enc=LabelEncoder() \n",
    "    label_enc.fit(list(data[col].values)) \n",
    "    data[col]=label_enc.transform(list(data[col].values))\n",
    "    \n",
    "data_x=data.iloc[:, :-1]    \n",
    "data_y=data.y\n",
    "\n",
    "data_x=preprocessing.scale(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.90988866151018\n",
      "Training F1 score: 0.90988866151018\n",
      "Recall score: 0.90988866151018\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     25580\n",
      "           1       0.66      0.41      0.51      3251\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     28831\n",
      "   macro avg       0.80      0.69      0.73     28831\n",
      "weighted avg       0.90      0.91      0.90     28831\n",
      "\n",
      "Test accuracy: 0.9126810714574735\n",
      "Test F1 score: 0.9126810714574733\n",
      "Recall score: 0.9126810714574735\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10968\n",
      "           1       0.68      0.43      0.53      1389\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     12357\n",
      "   macro avg       0.80      0.70      0.74     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(data_x, data_y, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg=LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, Y_train)\n",
    "Y_pred_train=log_reg.predict(X_train)\n",
    "print('Training accuracy:', accuracy_score(Y_train, Y_pred_train))\n",
    "print('Training F1 score:', f1_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Recall score:', recall_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Classification report:', classification_report(Y_train, Y_pred_train))\n",
    "\n",
    "Y_pred_test=log_reg.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(Y_test, Y_pred_test))\n",
    "print('Test F1 score:', f1_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Recall score:', recall_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Classification report:', classification_report(Y_test, Y_pred_test))\n",
    "\n",
    "skplt.metrics.plot_roc_curve(y_test, y_proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Training F1 score: 1.0\n",
      "Recall score: 1.0\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25580\n",
      "           1       1.00      1.00      1.00      3251\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     28831\n",
      "   macro avg       1.00      1.00      1.00     28831\n",
      "weighted avg       1.00      1.00      1.00     28831\n",
      "\n",
      "Test accuracy: 0.891964068948774\n",
      "Test F1 score: 0.891964068948774\n",
      "Recall score: 0.891964068948774\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     10968\n",
      "           1       0.52      0.53      0.52      1389\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     12357\n",
      "   macro avg       0.73      0.73      0.73     12357\n",
      "weighted avg       0.89      0.89      0.89     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt=tree.DecisionTreeClassifier().fit(X_train, Y_train)\n",
    "Y_pred_train=dt.predict(X_train)\n",
    "print('Training accuracy:', accuracy_score(Y_train, Y_pred_train))\n",
    "print('Training F1 score:', f1_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Recall score:', recall_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Classification report:', classification_report(Y_train, Y_pred_train))\n",
    "\n",
    "Y_pred_test=dt.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(Y_test, Y_pred_test))\n",
    "print('Test F1 score:', f1_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Recall score:', recall_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Classification report:', classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9004543720301065\n",
      "Training F1 score: 0.9004543720301065\n",
      "Recall score: 0.9004543720301065\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     25580\n",
      "           1       0.83      0.15      0.25      3251\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     28831\n",
      "   macro avg       0.86      0.57      0.60     28831\n",
      "weighted avg       0.89      0.90      0.87     28831\n",
      "\n",
      "Test accuracy: 0.9003803512179331\n",
      "Test F1 score: 0.9003803512179331\n",
      "Recall score: 0.9003803512179331\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     10968\n",
      "           1       0.85      0.14      0.24      1389\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     12357\n",
      "   macro avg       0.87      0.57      0.59     12357\n",
      "weighted avg       0.90      0.90      0.87     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0).fit(X_train, Y_train)\n",
    "Y_pred_train=rf.predict(X_train)\n",
    "print('Training accuracy:', accuracy_score(Y_train, Y_pred_train))\n",
    "print('Training F1 score:', f1_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Recall score:', recall_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Classification report:', classification_report(Y_train, Y_pred_train))\n",
    "\n",
    "Y_pred_test=rf.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(Y_test, Y_pred_test))\n",
    "print('Test F1 score:', f1_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Recall score:', recall_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Classification report:', classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.847039644826749\n",
      "Training F1 score: 0.847039644826749\n",
      "Recall score: 0.847039644826749\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91     25580\n",
      "           1       0.38      0.58      0.46      3251\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     28831\n",
      "   macro avg       0.66      0.73      0.69     28831\n",
      "weighted avg       0.88      0.85      0.86     28831\n",
      "\n",
      "Test accuracy: 0.8507728413045238\n",
      "Test F1 score: 0.8507728413045239\n",
      "Recall score: 0.8507728413045238\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     10968\n",
      "           1       0.39      0.60      0.47      1389\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     12357\n",
      "   macro avg       0.67      0.74      0.69     12357\n",
      "weighted avg       0.88      0.85      0.86     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb=GaussianNB().fit(X_train, Y_train)\n",
    "Y_pred_train=gnb.predict(X_train)\n",
    "print('Training accuracy:', accuracy_score(Y_train, Y_pred_train))\n",
    "print('Training F1 score:', f1_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Recall score:', recall_score(Y_train, Y_pred_train, average='micro'))\n",
    "print('Classification report:', classification_report(Y_train, Y_pred_train))\n",
    "\n",
    "Y_pred_test=gnb.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(Y_test, Y_pred_test))\n",
    "print('Test F1 score:', f1_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Recall score:', recall_score(Y_test, Y_pred_test, average='micro'))\n",
    "print('Classification report:', classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Analysis:\n",
    "    \n",
    "The best model for the regression task was the XGBoost regressor. This is because XGBoost is an ensemble method and hence it generalizes better. Therefore, the test set regression performance is the best for XGBoost regressor. I have used the following metrics for regression:\n",
    "- MSE\n",
    "- MAE\n",
    "- R2 score\n",
    "\n",
    "For the dataset processing, I have dropped the columns which have the same values across all data samples since they do not add any importance to the regression task. Totally I have considered 30 features as the regression features to fit on the dataset.\n",
    "\n",
    "Classification Analysis:\n",
    "    \n",
    "The best model for the classification task was the Logistic Regression model with no regularization. This is probably because of the bad fits of the other models. For the dataset, I have done no processing, I have taken all 20 features as is and scaled them by doing z-scoring.\n",
    "\n",
    "The metrics used were:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
